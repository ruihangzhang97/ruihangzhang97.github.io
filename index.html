<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Ruihang Zhang</title>
    <meta name="author" content="Ruihang Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="images/icon-rz.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Bio Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <span id="typing-text"></span>
                </p>
                <p>
                  I am a 4th year <a href="https://engsci.utoronto.ca/program/what-is-engsci/">Engineering Science</a> student at the University of Toronto, where I specialize in the Machine Intelligence option. My academic and research interests are <strong>3D Computer Vision</strong> and <strong>Generative Models</strong> with a focus on <strong>3D Digital Humans</strong> and <strong>Image/Video Generation</strong>. 
                </p>
                <p>
                  I am currently an undergraduate researcher working with <a href="https://felixtaubner.github.io/">Felix Taubner</a> and Professor <a href="https://davidlindell.com/">David Lindell</a> on <strong>Human-Centric Compositional Video Generation</strong>. Previously, I was a research intern with the Creative Vision team at <strong>Snap Research</strong>, working on <strong>Image Generation</strong> and <strong>Personalization</strong> with <a href="https://guochengqian.github.io/">Gordon Qian</a>, <a href="https://wangkua1.github.io/">Jackson Wang</a>, and <a href="https://stulyakov.com/">Sergey Tulyakov</a>, and an UTEA-funded undergraduate researcher in the <a href="http://www.modelics.org/">Modelics Lab</a>, with Professor <a href="https://www.ece.utoronto.ca/people/triverio-p/">Piero Triverio</a>, working on Dynamic CT analysis. 
                </p>
                <p>
                  Outside of academics, I am leading the Research Department at <a href="https://utmist.ca/">UTMIST</a>. I enjoy playing basketball and going to the gym. I have also been playing the piano and writing Chinese calligraphy since I was in elementary school. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:ruihang.zhang@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=KFx-0xIAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ruihangzhang97">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ruihang-zhang-3059b6243/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile-picture.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile-picture.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- News Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Updates</h2>
                <p>
                  <img src="images/snap-logo.png" style="width: 2em; height: 2em; vertical-align: middle; margin-right: 0.2em;"><strong>[May 2025 | Palo Alto]</strong> Joined <strong>Snap Research</strong> as a Research Intern<br>
                  <img src="images/tcig-logo.png" style="width: 2em; height: 2em; vertical-align: middle; margin-right: 0.2em;"><strong>[Sept 2025 | Toronto]</strong> Joined <strong>DGP</strong>/<strong>TCIG</strong> for undergrad thesis, with Felix Taubner & Professor David Lindell
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Publications Section -->
          <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle" colspan="2">
                  <h2>Publications</h2>
                </td>
              </tr>

              <!-- LayerComposer -->
              <tr bgcolor="#ffffd0">
                <td style="padding:16px;width:15%;vertical-align:middle">
                  <div class="one" onmouseover="layercomposer_start()" onmouseout="layercomposer_stop()">
                    <div class="two" id="layercomposer_video" style="opacity:0; transition: opacity 0.3s;">
                      <video width="100%" muted autoplay loop>
                        <source src="images/layer-composer.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src="images/layercomposer.png" width="100%">
                  </div>
                  <script type="text/javascript">
                    function layercomposer_start() {
                      document.getElementById('layercomposer_video').style.opacity = "1";
                    }
                    function layercomposer_stop() {
                      document.getElementById('layercomposer_video').style.opacity = "0";
                    }
                    layercomposer_stop();
                  </script>
                </td>
                <td style="padding:8px;width:85%;vertical-align:middle">
                  <a href="https://snap-research.github.io/layercomposer/">
                    <span class="papertitle">LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas</span>
                  </a>
                  <br>
                  <a href="https://guochengqian.github.io/">Gordon Guocheng Qian</a><sup>*</sup>,
                  <strong>Ruihang Zhang</strong><sup>*</sup>,
                  <a href="https://tsaishien-chen.github.io/">Tsai-Shien Chen</a>,
                  <a href="https://yusufdalva.github.io/">Yusuf Dalva</a>,
                  <a href="https://www.linkedin.com/in/anujraajgoel/">Anujraaj Goyal</a>,
                  <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                  <a href="https://skor.sh/">Ivan Skorokhodov</a>,
                  <a href="https://www.linkedin.com/in/danostashev/?originalSubdomain=uk">Daniil Ostashev</a>,
                  <a href="https://www.linkedin.com/in/meng-dong-744a69129/">Meng Dong</a>,
                  <a href="https://www.linkedin.com/in/arpitsah/">Arpit Sahni</a>,
                  <a href="https://www.linkedin.com/in/erichuju/">Ju Hu</a>,
                  <a href="https://stulyakov.com/">Sergey Tulyakov</a>,
                  <a href="https://wangkua1.github.io/">Kuan-Chieh Jackson Wang</a>
                  <br>
                  <small><strong><sup>*</sup>Equal Contribution, Co-First Authors</strong></small>
                  <br>
                  <em>Preprint</em>, 2025 
                  <br>
                  <a href="https://snap-research.github.io/layercomposer/">Project Page</a> /
                  <a href="https://arxiv.org/pdf/2510.20820">arXiv</a>
                  <p></p>
                  <p>
                    LayerComposer enables Photoshop-like control for multi-subject text-to-image generation, allowing users to compose scenes by placing, resizing, and locking elements in a layered canvas with high fidelity.
                  </p>
                </td>
              </tr>

              <!-- MVP4D -->
              <tr>
                <td style="padding:16px;width:15%;vertical-align:middle">
                  <div class="one" onmouseover="mvp4d_start()" onmouseout="mvp4d_stop()">
                    <div class="two" id="mvp4d_video" style="opacity:0; transition: opacity 0.3s;">
                      <video width="100%" muted autoplay loop>
                        <source src="images/mvp4d.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src="images/mvp4d.png" width="100%">
                  </div>
                  <script type="text/javascript">
                    function mvp4d_start() {
                      document.getElementById('mvp4d_video').style.opacity = "1";
                    }
                    function mvp4d_stop() {
                      document.getElementById('mvp4d_video').style.opacity = "0";
                    }
                    mvp4d_stop();
                  </script>
                </td>
                <td style="padding:8px;width:85%;vertical-align:middle">
                  <a href="https://felixtaubner.github.io/mvp4d/">
                    <span class="papertitle">MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars Diffusion Models</span>
                  </a>
                  <br>
                  <a href="https://felixtaubner.github.io/">Felix Taubner</a>,
                  <strong>Ruihang Zhang</strong>, 
                  <a href="https://mathieutuli.com/">Mathieu Tuli</a>,
                  <a href="https://sherwinbahmani.github.io/">Sherwin Bahmani</a>,
                  <a href="https://davidlindell.com/">David B. Lindell</a>
                  <br>
                  <em>SIGGRAPH ASIA</em>, 2025 
                  <br>
                  <a href="https://felixtaubner.github.io/mvp4d">Project Page</a> /
                  <a href="https://arxiv.org/pdf/2510.12785">arXiv</a>
                  <p></p>
                  <p>
                    MVP4D generates 360Â° human heads from a reference image and input animation using a Morphable Multi-View Video Diffusion Model, distilling them into a 4D representation for real-time rendering.
                  </p>
                </td>
              </tr>

              <!-- CAP4D -->
              <tr bgcolor="#ffffd0">
                <td style="padding:16px;width:15%;vertical-align:middle">
                  <div class="one" onmouseover="cap4d_start()" onmouseout="cap4d_stop()">
                    <div class="two" id="cap4d_video" style="opacity:0; transition: opacity 0.3s;">
                      <video width="100%" muted autoplay loop>
                        <source src="images/cap4d.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <img src="images/cap4d-picture.png" width="100%">
                  </div>
                  <script type="text/javascript">
                    function cap4d_start() {
                      document.getElementById('cap4d_video').style.opacity = "1";
                    }
                    function cap4d_stop() {
                      document.getElementById('cap4d_video').style.opacity = "0";
                    }
                    cap4d_stop();
                  </script>
                </td>
                <td style="padding:8px;width:85%;vertical-align:middle">
                  <a href="https://felixtaubner.github.io/cap4d/">
                    <span class="papertitle">CAP4D: Creating Animatable 4D Portrait Avatars with Morphable Multi-View Diffusion Models</span>
                  </a>
                  <br>
                  <a href="https://felixtaubner.github.io/">Felix Taubner</a>,
                  <strong>Ruihang Zhang</strong>, 
                  <a href="https://mathieutuli.com/">Mathieu Tuli</a>,
                  <a href="https://davidlindell.com/">David B. Lindell</a>
                  <br>
                  <em>CVPR</em>, 2025 (<span style="color: red;"><strong>Oral Presentation, 0.73%</strong></span>)
                  <br>
                  <a href="https://felixtaubner.github.io/cap4d/">Project Page</a> /
                  <a href="https://arxiv.org/abs/2412.12093">arXiv</a>
                  <p></p>
                  <p>
                    CAP4D generates controllable 4D human head avatars given any number of reference images using Morphable Multi-view Diffusion Models and Deformable 3D Gaussian Splatting.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- Attribution line at the bottom -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px;width:100%;vertical-align:middle">
                <div style="border-top: 1px solid #ddd; margin-top: 20px; padding-top: 20px;">
                  <p>
                    Website template from <a href="https://jonbarron.info/">Jonathan T. Barron</a>.
                  </p>
                </div>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </tbody></table>

    <script>
    document.addEventListener('DOMContentLoaded', function() {
      const text = "Ruihang Zhang";
      const element = document.getElementById('typing-text');
      let index = 0;

      function type() {
        element.textContent = text.slice(0, index);
        
        if (index < text.length) {
          index++;
          setTimeout(type, 150);
        }
      }

      type();
    });
    </script>
  </body>
</html>